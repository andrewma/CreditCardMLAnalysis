boost_table = table(card_test$card, y_pred)
accuracy = (sum(diag(boost_table)))/sum(boost_table)
accuracy
boost.card
accuracy
boost_table
library(xgboost)
data("CreditCard")
CreditCard = data.frame(CreditCard)
CreditCard$card <- ifelse(CreditCard$card=="yes", 1, 0)
CreditCard$owner <- ifelse(CreditCard$owner=="yes", 1, 0)
CreditCard$selfemp <- ifelse(CreditCard$selfemp=="yes", 1, 0)
card_train = CreditCard %>%
sample_frac(.70)
card_test = CreditCard %>%
setdiff(card_train)
Y_train <- as.matrix(card_train[,"card"])
X_train <- as.matrix(card_train[!names(card_train) %in% c("card")])
dtrain <- xgb.DMatrix(data = X_train, label = Y_train)
X_test <- as.matrix(card_test[!names(card_train) %in% c("card")])
set.seed(123)
set.seed(2)
card.xgb = xgboost(data=dtrain,
max_depth=2,
eta = 0.1,
nrounds=40, # max number of boosting iterations (trees)
lambda=0,
print_every_n = 10,
objective="binary:logistic")
yhat.xgb <- predict(card.xgb,X_test)
boost_table = table(yhat.xgb, card_test$card)
y_pred = ifelse(yhat.xgb>0.2,1,0)
boost_table = table(card_test$card, y_pred)
accuracy = (sum(diag(boost_table)))/sum(boost_table)
accuracy
boost.card
library(keras)
library(ISLR)
library(dplyr)
library(AER)
library(tensorflow)
data("CreditCard")
CreditCard = data.frame(CreditCard)
CreditCard$owner <- ifelse(CreditCard$owner=="yes", 1, 0)
CreditCard$selfemp <- ifelse(CreditCard$selfemp=="yes", 1, 0)
CreditCard$card_yes <- ifelse(CreditCard$card == "yes",1,0)
set.seed(123)
card_train = CreditCard %>%
sample_frac(.7)
card_test = CreditCard %>%
setdiff(card_train)
train_labels <- to_categorical(card_train[,"card_yes"],2)
train_data <- as.matrix(card_train[!names(card_train) %in% c("card","card_yes")])
test_data <- as.matrix(card_test[!names(card_train) %in% c("card","card_yes")])
test_labels <- to_categorical(card_test[,"card_yes"])
model <- keras_model_sequential() %>%
layer_dense(units = 64, activation = "softmax",
input_shape = dim(train_data)[2]) %>%
layer_dense(units = 64, activation = "softmax") %>%
layer_dense(units = 2, activation= "softmax")
model %>% compile(
loss = 'categorical_crossentropy',
optimizer = optimizer_rmsprop(),
metrics = c('accuracy')
)
early_stop <- callback_early_stopping(monitor = "val_loss", patience = 20)
epochs=200
history_class <- model %>% fit(
train_data,
train_labels,
epochs = epochs,
validation_split = 0.2,
callbacks = list(early_stop)
)
plot(history_class)
test_predictions <- model %>% predict(test_data)
test_class <- model %>% predict_classes(test_data)
error_table = table(test_labels[,2], test_class)
accuracy = (sum(diag(error_table)))/sum(error_table)
accuracy
data(CreditCard)
CreditCard$card01 <- ifelse(CreditCard$card=="yes", 1, 0)
attach(CreditCard)
# Boxplots
par(mfrow=c(2,4))
for(i in names(CreditCard)){
# excluding the own mpgs variables and others categorical variables
if( grepl(i, pattern="^card|owner|selfemp|name|majorcards")){ next}
boxplot(eval(parse(text=i)) ~ card01, ylab=i, main =paste(i, "boxplot"),
col=c("red", "blue"))
}
library(ISLR)
library(AER)
library(ggplot2)
data("CreditCard")
CreditCard = data.frame(CreditCard)
summary(CreditCard)
owner_hist<-ggplot(CreditCard, aes(x=owner), space = 50) +
geom_bar(fill="blue", width = 0.3) +
labs(title = "Histogram of Shares") +
theme(panel.background = element_blank())
owner_hist
selfemp_hist<-ggplot(CreditCard, aes(x=selfemp)) +
geom_bar(fill="blue", width = 0.3) +
labs(title = "Histogram of Selfemp") +
theme(panel.background = element_blank())
selfemp_hist
majorcards_hist<-ggplot(CreditCard, aes(x=majorcards)) +
geom_bar(fill="blue", width = 0.3) +
labs(title = "Histogram of majorcards") +
theme(panel.background = element_blank())
majorcards_hist
data(CreditCard)
CreditCard$card01 <- ifelse(CreditCard$card=="yes", 1, 0)
attach(CreditCard)
# Boxplots
par(mfrow=c(2,4))
for(i in names(CreditCard)){
# excluding the own mpgs variables and others categorical variables
if( grepl(i, pattern="^card|owner|selfemp|name|majorcards")){ next}
boxplot(eval(parse(text=i)) ~ card01, ylab=i, main =paste(i, "boxplot"),
col=c("red", "blue"))
}
glm.fits1 <- glm(card~reports+share+selfemp+majorcards+active,
data = CreditCard, family = binomial)
glm.probs1 = predict(glm.fits1,CreditCard,type="response")
glm.pred1 = rep(0,length(glm.probs1))
glm.pred1[glm.probs1>.90]=1
table1 = table(glm.pred1,CreditCard$card)
accuracy = (sum(diag(table1)))/sum(table1)
table1
accuracy
plot(reports,card01,xlab="reports",ylab="card01")
g=glm(card~reports,family=binomial,data = CreditCard)
curve(predict(g,data.frame(reports=x),type="resp"),add=TRUE)
library(class)
library(dplyr)
data("CreditCard")
CreditCard$card <- ifelse(CreditCard$card=="yes", 1, 0)
CreditCard$owner <- ifelse(CreditCard$owner=="yes", 1, 0)
CreditCard$selfemp <- ifelse(CreditCard$selfemp=="yes", 1, 0)
set.seed(123)
train = CreditCard %>% sample_frac(.7)
test = CreditCard %>% setdiff(train)
X_card_trn = train[, -1]
Y_card_trn = train$card
# testing data
X_card_tst = test[, -1]
Y_card_tst = test$card
card_pred = knn(train = scale(X_card_trn),
test  = scale(X_card_tst),
cl    = Y_card_trn,
k     = 12,
prob  = TRUE)
set.seed(123)
i=1
k.optm=1
for (i in 1:28){
knn.mod <- knn(train=X_card_trn, test=X_card_tst, cl=Y_card_trn, k=i)
k.optm[i] <- 100 * sum(Y_card_tst == knn.mod)/NROW(Y_card_tst)
k=i
cat(k,'=',k.optm[i],'')
}
plot(k.optm, type="b", xlab="K- Value",ylab="Accuracy level")
confusion_matrix = table(card_pred, Y_card_tst)
classification_rate = (sum(diag(confusion_matrix)))/sum(confusion_matrix)
classification_rate
library(ISLR)
library(AER)
library(ggplot2)
library(dplyr)
library(glmnet)
data("CreditCard")
CreditCard = data.frame(CreditCard)
names(CreditCard)
dim(CreditCard)
CreditCard$card <- ifelse(CreditCard$card=="yes", 1, 0)
CreditCard$owner <- ifelse(CreditCard$owner=="yes", 1, 0)
CreditCard$selfemp <- ifelse(CreditCard$selfemp=="yes", 1, 0)
library(caret)
library(dplyr)
library(glmnet)
data("CreditCard")
CreditCard = data.frame(CreditCard)
CreditCard$card <- ifelse(CreditCard$card=="yes", 1, 0)
CreditCard$owner <- ifelse(CreditCard$owner=="yes", 1, 0)
CreditCard$selfemp <- ifelse(CreditCard$selfemp=="yes", 1, 0)
set.seed(123)
train = CreditCard %>% sample_frac(.7)
test = CreditCard %>% setdiff(train)
x_train = model.matrix(card~., train)[,-1]
x_test = model.matrix(card~., test)[,-1]
y_train = train$card
y_test = test$card
x = model.matrix(card~., CreditCard)[,-1]
y = CreditCard$card
set.seed(123)
grid = 10^seq(5, -2, length = 100)
#grid = c(.1,.2,.3)
cv.out = cv.glmnet(x_train, y_train, alpha = 0, family = "binomial", lambda = grid)
bestlam = cv.out$lambda.1se
bestlam
plot(cv.out)
ridge_mod = glmnet(x_train, y_train, alpha = 0, lambda = grid, family = "binomial")
ridge_pred = predict(ridge_mod, s = bestlam, newx = x_test)
out = glmnet(x, y, alpha = 0, family = "binomial")
plot(out, xvar = "lambda")
ridge_coef = predict(out, type = "coefficients", s = bestlam)[1:12,]
ridge_coef
ridge_mod = glmnet(x_train, y_train, alpha = 0, lambda = bestlam, family = 'binomial')
ridge_pred = predict(ridge_mod, s = bestlam, newx = x_test)
y_pred = ifelse(ridge_pred>0.3,1,0)
table(y_pred, y_test)
set.seed(123)
grid = 10^seq(5, -2, length = 100)
#grid = c(.1,.2,.3)
cv.out = cv.glmnet(x_train, y_train, alpha = 1, family = "binomial", lambda = grid)
bestlam = cv.out$lambda.1se
bestlam
cv.lasso <- cv.glmnet(x_train, y_train, alpha = 1, family = "binomial")
plot(cv.lasso)
ridge_pred = predict(ridge_mod, s = bestlam, newx = x_test)
out = glmnet(x, y, alpha = 1, family = "binomial")
plot(out, xvar = "lambda")
ridge_coef = predict(out, type = "coefficients", s = bestlam)[1:12,]
ridge_coef
data("CreditCard")
CreditCard = data.frame(CreditCard)
CreditCard$owner <- ifelse(CreditCard$owner=="yes", 1, 0)
CreditCard$selfemp <- ifelse(CreditCard$selfemp=="yes", 1, 0)
CreditCard$card = as.factor(CreditCard$card)
train = CreditCard %>% sample_frac(.7)
test = CreditCard %>% setdiff(train)
library(tree)
tree_card=tree(card~., data =train)
plot(tree_card)
text(tree_card, pretty = 0)
tree_pred = predict(tree_card, test, type = "class")
tree_table = table(tree_pred, test$card)
accuracy = (sum(diag(tree_table)))/sum(tree_table)
accuracy
cv.card = cv.tree(tree_card, FUN = prune.misclass)
plot(cv.card$size, cv.card$dev, type = "b")
title("Credit Card Acceptance Classification Tree")
prune_card = prune.misclass(tree_card, best = 5)
plot(prune_card)
text(prune_card, pretty = 0)
tree_pred = predict(prune_card, test, type = "class")
prune_table = table(tree_pred, test$card)
accuracy = (sum(diag(prune_table)))/sum(prune_table)
accuracy
data("CreditCard")
CreditCard = data.frame(CreditCard)
library(randomForest)
set.seed(123)
card_train = CreditCard %>%
sample_frac(.70)
card_test = CreditCard %>%
setdiff(card_train)
set.seed(123)
bag.card = randomForest(card ~., data = card_train,
mtry=ncol(card_train) - 1,
importance=TRUE)
plot(bag.card, ylim=c(0.01, .05))
yhat.bag = predict(bag.card, newdata = card_test)
table(yhat.bag, card_test$card)
CM = table(yhat.bag, card_test$card)
accuracy = (sum(diag(CM)))/sum(CM)
accuracy
set.seed(123)
rf.card = randomForest(card~.,
data = card_train,
mtry = 5,
importance = TRUE,
do.trace = 100)
plot(rf.card, ylim = c(0, 0.03))
rm(list=ls())
library(gbm)
library(randomForest)
data("CreditCard")
ls(CreditCard)
CreditCard$card <- ifelse(CreditCard$card=="yes", 1, 0)
#CreditCard$owner <- ifelse(CreditCard$owner=="yes", 1, 0)
#CreditCard$selfemp <- ifelse(CreditCard$selfemp=="yes", 1, 0)
set.seed(123)
card_train = CreditCard %>%
sample_frac(.70)
card_test = CreditCard %>%
setdiff(card_train)
set.seed(123)
boost.card = gbm(card~.,
data = card_train,
distribution = "bernoulli",
n.trees = 500,
interaction.depth = 4)
summary(boost.card)
yhat.boost = predict(boost.card,
newdata = card_test,
n.trees = 5000)
boost_pred = predict(boost.card, card_test, n.trees=500, type = "response")
y_pred = ifelse(boost_pred>0.2,1,0)
boost_table = table(card_test$card, y_pred)
accuracy = (sum(diag(boost_table)))/sum(boost_table)
accuracy
boost.card
accuracy
boost_table
library(xgboost)
data("CreditCard")
CreditCard = data.frame(CreditCard)
CreditCard$card <- ifelse(CreditCard$card=="yes", 1, 0)
CreditCard$owner <- ifelse(CreditCard$owner=="yes", 1, 0)
CreditCard$selfemp <- ifelse(CreditCard$selfemp=="yes", 1, 0)
card_train = CreditCard %>%
sample_frac(.70)
card_test = CreditCard %>%
setdiff(card_train)
Y_train <- as.matrix(card_train[,"card"])
X_train <- as.matrix(card_train[!names(card_train) %in% c("card")])
dtrain <- xgb.DMatrix(data = X_train, label = Y_train)
X_test <- as.matrix(card_test[!names(card_train) %in% c("card")])
set.seed(123)
set.seed(2)
card.xgb = xgboost(data=dtrain,
max_depth=2,
eta = 0.1,
nrounds=40, # max number of boosting iterations (trees)
lambda=0,
print_every_n = 10,
objective="binary:logistic")
yhat.xgb <- predict(card.xgb,X_test)
boost_table = table(yhat.xgb, card_test$card)
y_pred = ifelse(yhat.xgb>0.2,1,0)
boost_table = table(card_test$card, y_pred)
accuracy = (sum(diag(boost_table)))/sum(boost_table)
accuracy
boost.card
library(keras)
library(ISLR)
library(dplyr)
library(AER)
library(tensorflow)
data("CreditCard")
CreditCard = data.frame(CreditCard)
CreditCard$owner <- ifelse(CreditCard$owner=="yes", 1, 0)
CreditCard$selfemp <- ifelse(CreditCard$selfemp=="yes", 1, 0)
CreditCard$card_yes <- ifelse(CreditCard$card == "yes",1,0)
set.seed(123)
card_train = CreditCard %>%
sample_frac(.7)
card_test = CreditCard %>%
setdiff(card_train)
train_labels <- to_categorical(card_train[,"card_yes"],2)
train_data <- as.matrix(card_train[!names(card_train) %in% c("card","card_yes")])
test_data <- as.matrix(card_test[!names(card_train) %in% c("card","card_yes")])
test_labels <- to_categorical(card_test[,"card_yes"])
model <- keras_model_sequential() %>%
layer_dense(units = 64, activation = "softmax",
input_shape = dim(train_data)[2]) %>%
layer_dense(units = 64, activation = "softmax") %>%
layer_dense(units = 2, activation= "softmax")
model %>% compile(
loss = 'categorical_crossentropy',
optimizer = optimizer_rmsprop(),
metrics = c('accuracy')
)
early_stop <- callback_early_stopping(monitor = "val_loss", patience = 20)
epochs=200
history_class <- model %>% fit(
train_data,
train_labels,
epochs = epochs,
validation_split = 0.2,
callbacks = list(early_stop)
)
plot(history_class)
test_predictions <- model %>% predict(test_data)
test_class <- model %>% predict_classes(test_data)
error_table = table(test_labels[,2], test_class)
accuracy = (sum(diag(error_table)))/sum(error_table)
accuracy
library(ISLR)
library(AER)
library(ggplot2)
data("CreditCard")
CreditCard = data.frame(CreditCard)
summary(CreditCard)
owner_hist<-ggplot(CreditCard, aes(x=owner), space = 50) +
geom_bar(fill="blue", width = 0.3) +
labs(title = "Histogram of Shares") +
theme(panel.background = element_blank())
owner_hist
selfemp_hist<-ggplot(CreditCard, aes(x=selfemp)) +
geom_bar(fill="blue", width = 0.3) +
labs(title = "Histogram of Selfemp") +
theme(panel.background = element_blank())
selfemp_hist
majorcards_hist<-ggplot(CreditCard, aes(x=majorcards)) +
geom_bar(fill="blue", width = 0.3) +
labs(title = "Histogram of majorcards") +
theme(panel.background = element_blank())
majorcards_hist
data(CreditCard)
CreditCard$card01 <- ifelse(CreditCard$card=="yes", 1, 0)
attach(CreditCard)
# Boxplots
par(mfrow=c(2,4))
for(i in names(CreditCard)){
# excluding the own mpgs variables and others categorical variables
if( grepl(i, pattern="^card|owner|selfemp|name|majorcards")){ next}
boxplot(eval(parse(text=i)) ~ card01, ylab=i, main =paste(i, "boxplot"),
col=c("red", "blue"))
}
glm.fits1 <- glm(card~reports+share+selfemp+majorcards+active,
data = CreditCard, family = binomial)
glm.probs1 = predict(glm.fits1,CreditCard,type="response")
glm.pred1 = rep(0,length(glm.probs1))
glm.pred1[glm.probs1>.90]=1
table1 = table(glm.pred1,CreditCard$card)
accuracy = (sum(diag(table1)))/sum(table1)
table1
accuracy
plot(reports,card01,xlab="reports",ylab="card01")
g=glm(card~reports,family=binomial,data = CreditCard)
curve(predict(g,data.frame(reports=x),type="resp"),add=TRUE)
library(class)
library(dplyr)
data("CreditCard")
CreditCard$card <- ifelse(CreditCard$card=="yes", 1, 0)
CreditCard$owner <- ifelse(CreditCard$owner=="yes", 1, 0)
CreditCard$selfemp <- ifelse(CreditCard$selfemp=="yes", 1, 0)
set.seed(123)
train = CreditCard %>% sample_frac(.7)
test = CreditCard %>% setdiff(train)
X_card_trn = train[, -1]
Y_card_trn = train$card
# testing data
X_card_tst = test[, -1]
Y_card_tst = test$card
card_pred = knn(train = scale(X_card_trn),
test  = scale(X_card_tst),
cl    = Y_card_trn,
k     = 12,
prob  = TRUE)
set.seed(123)
i=1
k.optm=1
for (i in 1:28){
knn.mod <- knn(train=X_card_trn, test=X_card_tst, cl=Y_card_trn, k=i)
k.optm[i] <- 100 * sum(Y_card_tst == knn.mod)/NROW(Y_card_tst)
k=i
cat(k,'=',k.optm[i],'')
}
plot(k.optm, type="b", xlab="K- Value",ylab="Accuracy level")
confusion_matrix = table(card_pred, Y_card_tst)
classification_rate = (sum(diag(confusion_matrix)))/sum(confusion_matrix)
classification_rate
library(ISLR)
library(AER)
library(ggplot2)
library(dplyr)
library(glmnet)
data("CreditCard")
CreditCard = data.frame(CreditCard)
names(CreditCard)
dim(CreditCard)
CreditCard$card <- ifelse(CreditCard$card=="yes", 1, 0)
CreditCard$owner <- ifelse(CreditCard$owner=="yes", 1, 0)
CreditCard$selfemp <- ifelse(CreditCard$selfemp=="yes", 1, 0)
library(caret)
library(dplyr)
library(glmnet)
data("CreditCard")
CreditCard = data.frame(CreditCard)
CreditCard$card <- ifelse(CreditCard$card=="yes", 1, 0)
CreditCard$owner <- ifelse(CreditCard$owner=="yes", 1, 0)
CreditCard$selfemp <- ifelse(CreditCard$selfemp=="yes", 1, 0)
set.seed(123)
train = CreditCard %>% sample_frac(.7)
test = CreditCard %>% setdiff(train)
x_train = model.matrix(card~., train)[,-1]
x_test = model.matrix(card~., test)[,-1]
y_train = train$card
y_test = test$card
x = model.matrix(card~., CreditCard)[,-1]
y = CreditCard$card
set.seed(123)
grid = 10^seq(5, -2, length = 100)
#grid = c(.1,.2,.3)
cv.out = cv.glmnet(x_train, y_train, alpha = 0, family = "binomial", lambda = grid)
bestlam = cv.out$lambda.1se
bestlam
plot(cv.out)
ridge_mod = glmnet(x_train, y_train, alpha = 0, lambda = grid, family = "binomial")
ridge_pred = predict(ridge_mod, s = bestlam, newx = x_test)
out = glmnet(x, y, alpha = 0, family = "binomial")
plot(out, xvar = "lambda")
ridge_coef = predict(out, type = "coefficients", s = bestlam)[1:12,]
ridge_coef
ridge_mod = glmnet(x_train, y_train, alpha = 0, lambda = bestlam, family = 'binomial')
ridge_pred = predict(ridge_mod, s = bestlam, newx = x_test)
y_pred = ifelse(ridge_pred>0.3,1,0)
table(y_pred, y_test)
set.seed(123)
grid = 10^seq(5, -2, length = 100)
#grid = c(.1,.2,.3)
cv.out = cv.glmnet(x_train, y_train, alpha = 1, family = "binomial", lambda = grid)
bestlam = cv.out$lambda.1se
bestlam
cv.lasso <- cv.glmnet(x_train, y_train, alpha = 1, family = "binomial")
savehistory(file = ".Rhistory")
savehistory(file = ".Rhistory")
